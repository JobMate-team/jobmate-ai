### cli_main.py
import os
import json
import re
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain_core.documents import Document
from openai import OpenAI

# ì„¤ì •
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")

embedding = OpenAIEmbeddings(api_key=api_key)
client = OpenAI(api_key=api_key)

# 1. FAISS DB ìƒì„± í•¨ìˆ˜
def build_faiss_from_json(folder_path="./embedding"):
    docs = []
    for filename in ["question_templates.json", "answer_patterns.json", "competency_rubrics.json", "model_answers.json"]:
        filepath = os.path.join(folder_path, filename)
        if not os.path.exists(filepath):
            print(f"âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {filepath}")
            continue
        with open(filepath, "r", encoding="utf-8") as f:
            items = json.load(f)
            for item in items:
                docs.append(Document(page_content=item["page_content"], metadata=item["metadata"]))

    vectorstore = FAISS.from_documents(docs, embedding)
    vectorstore.save_local("faiss_index")
    print("âœ… FAISS ë²¡í„° DB ìƒì„± ì™„ë£Œ")

# 2. í”„ë¡¬í”„íŠ¸ ìƒì„± í…œí”Œë¦¿
def build_prompt(question, answer, context):
    return f"""
ë„ˆëŠ” ì‹ ì… ë°±ì—”ë“œ ê°œë°œìì˜ ë©´ì ‘ ì½”ì¹˜ì…ë‹ˆë‹¤.
ë‹µë³€ì„ í‰ê°€í•  ë•ŒëŠ” ë¬¸ì œ í•´ê²°ë ¥, ê¸°ìˆ  ì´í•´ë„, ì „ë‹¬ë ¥ì„ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.
ë‹µë³€ êµ¬ì¡°ê°€ STARì— ì í•©í•œì§€, ê° ë‹¨ê³„ê°€ ì˜ í‘œí˜„ë˜ì—ˆëŠ”ì§€ ìœ ì‹¬íˆ ì‚´í´ë³´ì„¸ìš”.

[ë©´ì ‘ ì§ˆë¬¸]
{question}

[ì‚¬ìš©ì ë‹µë³€]
{answer}

[ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ (ì°¸ê³  ìë£Œ)]
{context}

[ìš”ì²­ì‚¬í•­]
1. ìœ„ ë‹µë³€ì— ëŒ€í•´ í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”.
   - ì–´ë–¤ ì ì´ ì¢‹ê³  ì–´ë–¤ ì ì´ ë¶€ì¡±í•œì§€ ì„œìˆ 
   - í•„ìš”í•œ ê²½ìš° ê°œì„  ì œì•ˆì„ í¬í•¨í•˜ì„¸ìš”

2. í•´ë‹¹ ë‹µë³€ì„ STAR êµ¬ì¡°ë¡œ ë¶„ì„í•˜ì—¬ ê° ìš”ì†Œë³„ë¡œ ì ìˆ˜ë¥¼ ë§¤ê¸°ê³  ì½”ë©˜íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
   - ì˜ˆì‹œ:
     - Situation: 3/5 - ë°°ê²½ ì„¤ëª…ì´ ëª¨í˜¸í•¨
     - Task: 4/5 - ëª©í‘œê°€ ëª…í™•í•˜ê²Œ í‘œí˜„ë¨
     - Action: 2/5 - êµ¬ì²´ì ì¸ í–‰ë™ ì„¤ëª…ì´ ë¶€ì¡±í•¨
     - Result: 3/5 - ì„±ê³¼ê°€ ëšœë ·í•˜ì§€ ì•ŠìŒ

3. ê°œì„ ëœ ë‹µë³€(ëª¨ë²”ë‹µë³€)ì„ STAR êµ¬ì¡°ì— ë§ì¶° ë‹¤ì‹œ ì‘ì„±í•´ì£¼ì„¸ìš”.
   - ê° ë‹¨ê³„ë³„ë¡œ êµ¬ë¶„í•´ì„œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""

# 3. ì‘ë‹µ íŒŒì‹± í•¨ìˆ˜
def parse_star_feedback(output):
    star_scores = {}
    pattern = r"(Situation|Task|Action|Result):\s*(\d)/(\d)\s*-\s*(.*)"
    matches = re.findall(pattern, output)
    for section, score, total, comment in matches:
        star_scores[section] = {
            "score": int(score),
            "out_of": int(total),
            "comment": comment.strip()
        }
    return star_scores

# 4. ì‚¬ìš©ì ì…ë ¥ í›„ RAG ê¸°ë°˜ ì‘ë‹µ ìƒì„±
def run_rag_interaction():
    db = FAISS.load_local("faiss_index", embedding, allow_dangerous_deserialization=True)

    print("[ë©´ì ‘ ì§ˆë¬¸ ì…ë ¥]")
    question = input("Q: ")
    print("[ì‚¬ìš©ì ë‹µë³€ ì…ë ¥]")
    answer = input("A: ")

    docs = db.similarity_search(question, k=4)
    context = "\n\n".join([doc.page_content for doc in docs])

    prompt = build_prompt(question, answer, context)

    completion = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ë„Œ ë©´ì ‘ í”¼ë“œë°± ì½”ì¹˜ì•¼."},
            {"role": "user", "content": prompt}
        ]
    )

    output = completion.choices[0].message.content
    print("\nğŸ“Œ ì „ì²´ ì‘ë‹µ:\n")
    print(output)

    # STAR ì ìˆ˜ íŒŒì‹±
    star_feedback = parse_star_feedback(output)
    print("\nğŸ“Š STAR êµ¬ì¡° í‰ê°€ ê²°ê³¼:")
    for section, data in star_feedback.items():
        print(f"- {section}: {data['score']}/{data['out_of']} - {data['comment']}")

# ì‹¤í–‰
def main():
    if not os.path.exists("faiss_index"):
        build_faiss_from_json()
    run_rag_interaction()

if __name__ == "__main__":
    main()
